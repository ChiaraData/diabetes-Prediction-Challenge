{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0b74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 1. Chargement\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test_ids = test['id']\n",
    "\n",
    "# 2. Feature Engineering (Train & Test)\n",
    "for df in [train, test]:\n",
    "    df['cholesterol_ratio'] = df['ldl_cholesterol'] / df['hdl_cholesterol']\n",
    "    df['mean_blood_pressure'] = (df['systolic_bp'] + df['diastolic_bp']) / 2\n",
    "\n",
    "# 3. Encodage Ordinal\n",
    "income_map = {'Low': 1, 'Lower-Middle': 2, 'Middle': 3, 'Upper-Middle': 4, 'High': 5}\n",
    "edu_map = {'No formal': 0, 'Highschool': 1, 'Graduate': 2, 'Postgraduate': 3}\n",
    "smoke_map = {'Never': 0, 'Current': 1, 'Former': 2}\n",
    "\n",
    "for df in [train, test]:\n",
    "    df['income_level'] = df['income_level'].map(income_map)\n",
    "    df['education_level'] = df['education_level'].map(edu_map)\n",
    "    df['smoking_status'] = df['smoking_status'].map(smoke_map)\n",
    "\n",
    "# 4. One-Hot Encoding\n",
    "nominal_cols = ['gender', 'ethnicity', 'employment_status']\n",
    "train = pd.get_dummies(train, columns=nominal_cols, drop_first=True, dtype=int)\n",
    "test = pd.get_dummies(test, columns=nominal_cols, drop_first=True, dtype=int)\n",
    "\n",
    "# 5. Séparation X/y et Alignement\n",
    "X_train = train.drop(columns=['id', 'diagnosed_diabetes'])\n",
    "y_train = train['diagnosed_diabetes']\n",
    "X_test = test.drop(columns=['id']).reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# 6. Standardisation (Fit sur Train uniquement)\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# 7. Modèle Final (Vos meilleurs paramètres)\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.25, \n",
    "    n_estimators=300, \n",
    "    max_depth=3, \n",
    "    subsample=0.8, \n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. Création du fichier CSV\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "submission = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': probs})\n",
    "submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae2f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement en cours...\n",
      "Nouveau score AUC-ROC Local : 0.70926\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 1. Chargement des données\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "test_ids = df_test['id']\n",
    "\n",
    "# 2. Nettoyage des Outliers (Clipping pour limiter l'impact des valeurs extrêmes)\n",
    "# On limite le BMI à 60 et la pression systolique à 200 pour éviter le bruit\n",
    "for df in [df_train, df_test]:\n",
    "    df['bmi'] = df['bmi'].clip(upper=60)\n",
    "    df['systolic_bp'] = df['systolic_bp'].clip(upper=200)\n",
    "\n",
    "# 3. Feature Engineering\n",
    "for df in [df_train, df_test]:\n",
    "    df['cholesterol_ratio'] = df['ldl_cholesterol'] / (df['hdl_cholesterol'] + 0.001)\n",
    "    df['mean_blood_pressure'] = (df['systolic_bp'] + df['diastolic_bp']) / 2\n",
    "    # Bonus : Indicateur d'activité physique (Minutes / Age)\n",
    "    df['activity_intensity'] = df['physical_activity_minutes_per_week'] / (df['age'] + 1)\n",
    "\n",
    "# 4. Encodage Ordinal\n",
    "income_map = {'Low': 1, 'Lower-Middle': 2, 'Middle': 3, 'Upper-Middle': 4, 'High': 5}\n",
    "edu_map = {'No formal': 0, 'Highschool': 1, 'Graduate': 2, 'Postgraduate': 3}\n",
    "smoke_map = {'Never': 0, 'Current': 1, 'Former': 2}\n",
    "\n",
    "for df in [df_train, df_test]:\n",
    "    df['income_level'] = df['income_level'].map(income_map)\n",
    "    df['education_level'] = df['education_level'].map(edu_map)\n",
    "    df['smoking_status'] = df['smoking_status'].map(smoke_map)\n",
    "\n",
    "# 5. One-Hot Encoding\n",
    "nominal_cols = ['gender', 'ethnicity', 'employment_status']\n",
    "df_train = pd.get_dummies(df_train, columns=nominal_cols, drop_first=True, dtype=int)\n",
    "df_test = pd.get_dummies(df_test, columns=nominal_cols, drop_first=True, dtype=int)\n",
    "\n",
    "# 6. Préparation des colonnes et division\n",
    "X = df_train.drop(columns=['id', 'diagnosed_diabetes'])\n",
    "y = df_train['diagnosed_diabetes']\n",
    "\n",
    "# Aligner le test sur le train (colonnes identiques)\n",
    "X_test_final = df_test.drop(columns=['id']).reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Split pour validation locale (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 7. Standardisation stricte\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_val[num_cols] = scaler.transform(X_val[num_cols])\n",
    "X_test_final[num_cols] = scaler.transform(X_test_final[num_cols])\n",
    "\n",
    "# 8. Modèle robuste (Paramètres anti-overfitting)\n",
    "# On réduit le learning rate et on augmente les arbres\n",
    "stable_gb = GradientBoostingClassifier(\n",
    "    learning_rate=0.05,  # Plus lent = plus stable\n",
    "    n_estimators=800,    # Plus d'arbres pour compenser la lenteur\n",
    "    max_depth=3,         # On garde des arbres simples\n",
    "    subsample=0.8,       # Utilise 80% des données par arbre (Stochastic)\n",
    "    max_features='sqrt', # Sélectionne un sous-ensemble de variables pour chaque split\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Entraînement en cours...\")\n",
    "stable_gb.fit(X_train, y_train)\n",
    "\n",
    "# 9. Validation locale\n",
    "val_probs = stable_gb.predict_proba(X_val)[:, 1]\n",
    "print(f\"Nouveau score AUC-ROC Local : {roc_auc_score(y_val, val_probs):.5f}\")\n",
    "\n",
    "# 10. Génération du fichier pour Kaggle\n",
    "test_probs = stable_gb.predict_proba(X_test_final)[:, 1]\n",
    "submission = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_probs})\n",
    "submission.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b69c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la Cross-Validation...\n",
      "Fold 1 terminé.\n",
      "Fold 2 terminé.\n",
      "Fold 3 terminé.\n",
      "Fold 4 terminé.\n",
      "Fold 5 terminé.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 1. Chargement\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test_ids = test['id']\n",
    "\n",
    "# 2. Feature Engineering minimal (les deux qui marchaient bien)\n",
    "for df in [train, test]:\n",
    "    df['cholesterol_ratio'] = df['ldl_cholesterol'] / (df['hdl_cholesterol'] + 0.001)\n",
    "    df['mean_blood_pressure'] = (df['systolic_bp'] + df['diastolic_bp']) / 2\n",
    "\n",
    "# 3. Encodage express\n",
    "train['income_level'] = train['income_level'].map({'Low':1,'Lower-Middle':2,'Middle':3,'Upper-Middle':4,'High':5})\n",
    "test['income_level'] = test['income_level'].map({'Low':1,'Lower-Middle':2,'Middle':3,'Upper-Middle':4,'High':5})\n",
    "# On simplifie : on ne garde que les numériques et l'income pour ce test\n",
    "features = train.select_dtypes(include=[np.number]).columns.drop(['id', 'diagnosed_diabetes']).tolist()\n",
    "\n",
    "X = train[features]\n",
    "y = train['diagnosed_diabetes']\n",
    "X_test = test[features]\n",
    "\n",
    "# 4. Cross-Validation (5-Folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "test_preds = np.zeros(len(X_test))\n",
    "val_scores = []\n",
    "\n",
    "print(\"Démarrage de la Cross-Validation...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_tr, X_va = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_tr, y_va = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Standardisation\n",
    "    scaler = StandardScaler()\n",
    "    X_tr = scaler.fit_transform(X_tr)\n",
    "    X_va = scaler.transform(X_va)\n",
    "    X_te = scaler.transform(X_test)\n",
    "    \n",
    "    # Modèle équilibré\n",
    "    model = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Accumulation des prédictions\n",
    "    test_preds += model.predict_proba(X_te)[:, 1] / 5\n",
    "    print(f\"Fold {fold+1} terminé.\")\n",
    "\n",
    "# 5. Soumission\n",
    "submission = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_preds})\n",
    "submission.to_csv('submission4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fcb544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6843221\tbest: 0.6843221 (0)\ttotal: 352ms\tremaining: 11m 43s\n",
      "200:\ttest: 0.7087498\tbest: 0.7087498 (200)\ttotal: 48s\tremaining: 7m 9s\n",
      "400:\ttest: 0.7137586\tbest: 0.7137586 (400)\ttotal: 1m 39s\tremaining: 6m 35s\n",
      "600:\ttest: 0.7200688\tbest: 0.7200688 (600)\ttotal: 2m 34s\tremaining: 5m 58s\n",
      "800:\ttest: 0.7225045\tbest: 0.7225045 (800)\ttotal: 3m 33s\tremaining: 5m 19s\n",
      "1000:\ttest: 0.7239158\tbest: 0.7239158 (1000)\ttotal: 4m 32s\tremaining: 4m 31s\n",
      "1200:\ttest: 0.7249532\tbest: 0.7249532 (1200)\ttotal: 5m 29s\tremaining: 3m 38s\n",
      "1400:\ttest: 0.7255281\tbest: 0.7255322 (1399)\ttotal: 6m 26s\tremaining: 2m 45s\n",
      "1600:\ttest: 0.7259988\tbest: 0.7260014 (1594)\ttotal: 7m 26s\tremaining: 1m 51s\n",
      "1800:\ttest: 0.7263739\tbest: 0.7263773 (1798)\ttotal: 8m 27s\tremaining: 56.1s\n",
      "1999:\ttest: 0.7266647\tbest: 0.7266652 (1998)\ttotal: 9m 25s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7266652358\n",
      "bestIteration = 1998\n",
      "\n",
      "Shrink model to first 1999 iterations.\n",
      "Fold 1 AUC: 0.72667\n",
      "0:\ttest: 0.6807939\tbest: 0.6807939 (0)\ttotal: 333ms\tremaining: 11m 5s\n",
      "200:\ttest: 0.7068095\tbest: 0.7068095 (200)\ttotal: 1m\tremaining: 8m 58s\n",
      "400:\ttest: 0.7126133\tbest: 0.7126133 (400)\ttotal: 2m 6s\tremaining: 8m 24s\n",
      "600:\ttest: 0.7183592\tbest: 0.7183592 (600)\ttotal: 3m 3s\tremaining: 7m 7s\n",
      "800:\ttest: 0.7206705\tbest: 0.7206705 (800)\ttotal: 4m 4s\tremaining: 6m 6s\n",
      "1000:\ttest: 0.7220600\tbest: 0.7220600 (1000)\ttotal: 5m 3s\tremaining: 5m 3s\n",
      "1200:\ttest: 0.7230735\tbest: 0.7230735 (1200)\ttotal: 6m\tremaining: 4m\n",
      "1400:\ttest: 0.7236245\tbest: 0.7236253 (1397)\ttotal: 7m 1s\tremaining: 3m\n",
      "1600:\ttest: 0.7241207\tbest: 0.7241215 (1599)\ttotal: 7m 58s\tremaining: 1m 59s\n",
      "1800:\ttest: 0.7244377\tbest: 0.7244377 (1800)\ttotal: 8m 55s\tremaining: 59.1s\n",
      "1999:\ttest: 0.7247054\tbest: 0.7247054 (1999)\ttotal: 9m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7247053748\n",
      "bestIteration = 1999\n",
      "\n",
      "Fold 2 AUC: 0.72471\n",
      "0:\ttest: 0.6819267\tbest: 0.6819267 (0)\ttotal: 321ms\tremaining: 10m 40s\n",
      "200:\ttest: 0.7073068\tbest: 0.7073068 (200)\ttotal: 1m 3s\tremaining: 9m 24s\n",
      "400:\ttest: 0.7124585\tbest: 0.7124585 (400)\ttotal: 1m 59s\tremaining: 7m 55s\n",
      "600:\ttest: 0.7185622\tbest: 0.7185622 (600)\ttotal: 2m 59s\tremaining: 6m 57s\n",
      "800:\ttest: 0.7212159\tbest: 0.7212159 (800)\ttotal: 4m 2s\tremaining: 6m 2s\n",
      "1000:\ttest: 0.7228356\tbest: 0.7228356 (1000)\ttotal: 5m 8s\tremaining: 5m 7s\n",
      "1200:\ttest: 0.7238327\tbest: 0.7238327 (1200)\ttotal: 6m 13s\tremaining: 4m 8s\n",
      "1400:\ttest: 0.7245148\tbest: 0.7245148 (1400)\ttotal: 7m 19s\tremaining: 3m 7s\n",
      "1600:\ttest: 0.7250434\tbest: 0.7250434 (1600)\ttotal: 8m 25s\tremaining: 2m 5s\n",
      "1800:\ttest: 0.7255144\tbest: 0.7255163 (1799)\ttotal: 9m 31s\tremaining: 1m 3s\n",
      "1999:\ttest: 0.7257613\tbest: 0.7257613 (1999)\ttotal: 10m 38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7257612746\n",
      "bestIteration = 1999\n",
      "\n",
      "Fold 3 AUC: 0.72576\n",
      "0:\ttest: 0.6824828\tbest: 0.6824828 (0)\ttotal: 297ms\tremaining: 9m 54s\n",
      "200:\ttest: 0.7084968\tbest: 0.7084968 (200)\ttotal: 1m 6s\tremaining: 9m 51s\n",
      "400:\ttest: 0.7137964\tbest: 0.7137964 (400)\ttotal: 2m 16s\tremaining: 9m 2s\n",
      "600:\ttest: 0.7200621\tbest: 0.7200621 (600)\ttotal: 3m 24s\tremaining: 7m 56s\n",
      "800:\ttest: 0.7225815\tbest: 0.7225815 (800)\ttotal: 4m 32s\tremaining: 6m 48s\n",
      "1000:\ttest: 0.7241722\tbest: 0.7241722 (1000)\ttotal: 5m 41s\tremaining: 5m 41s\n",
      "1200:\ttest: 0.7252186\tbest: 0.7252186 (1200)\ttotal: 6m 49s\tremaining: 4m 32s\n",
      "1400:\ttest: 0.7258444\tbest: 0.7258463 (1399)\ttotal: 7m 56s\tremaining: 3m 23s\n",
      "1600:\ttest: 0.7262866\tbest: 0.7262881 (1594)\ttotal: 9m 16s\tremaining: 2m 18s\n",
      "1800:\ttest: 0.7266081\tbest: 0.7266150 (1794)\ttotal: 10m 38s\tremaining: 1m 10s\n",
      "1999:\ttest: 0.7269880\tbest: 0.7269880 (1999)\ttotal: 11m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7269879645\n",
      "bestIteration = 1999\n",
      "\n",
      "Fold 4 AUC: 0.72699\n",
      "0:\ttest: 0.6829379\tbest: 0.6829379 (0)\ttotal: 371ms\tremaining: 12m 22s\n",
      "200:\ttest: 0.7081130\tbest: 0.7081130 (200)\ttotal: 1m 14s\tremaining: 11m 7s\n",
      "400:\ttest: 0.7136328\tbest: 0.7136328 (400)\ttotal: 2m 21s\tremaining: 9m 23s\n",
      "600:\ttest: 0.7197780\tbest: 0.7197780 (600)\ttotal: 3m 48s\tremaining: 8m 51s\n",
      "800:\ttest: 0.7222753\tbest: 0.7222753 (800)\ttotal: 5m 32s\tremaining: 8m 17s\n",
      "1000:\ttest: 0.7237387\tbest: 0.7237387 (1000)\ttotal: 6m 58s\tremaining: 6m 57s\n",
      "1200:\ttest: 0.7246583\tbest: 0.7246583 (1200)\ttotal: 8m 7s\tremaining: 5m 24s\n",
      "1400:\ttest: 0.7252929\tbest: 0.7252929 (1400)\ttotal: 9m 14s\tremaining: 3m 57s\n",
      "1600:\ttest: 0.7258353\tbest: 0.7258353 (1600)\ttotal: 10m 20s\tremaining: 2m 34s\n",
      "1800:\ttest: 0.7261444\tbest: 0.7261457 (1799)\ttotal: 11m 27s\tremaining: 1m 15s\n",
      "1999:\ttest: 0.7263856\tbest: 0.7263865 (1992)\ttotal: 12m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7263864747\n",
      "bestIteration = 1992\n",
      "\n",
      "Shrink model to first 1993 iterations.\n",
      "Fold 5 AUC: 0.72639\n",
      "\n",
      "Mean CV AUC: 0.726101264867103\n",
      "0:\ttotal: 401ms\tremaining: 13m 17s\n",
      "200:\ttotal: 1m 18s\tremaining: 11m 35s\n",
      "400:\ttotal: 2m 45s\tremaining: 10m 57s\n",
      "600:\ttotal: 4m 3s\tremaining: 9m 24s\n",
      "800:\ttotal: 5m 46s\tremaining: 8m 35s\n",
      "1000:\ttotal: 7m 8s\tremaining: 7m 3s\n",
      "1200:\ttotal: 8m 15s\tremaining: 5m 26s\n",
      "1400:\ttotal: 9m 20s\tremaining: 3m 56s\n",
      "1600:\ttotal: 10m 23s\tremaining: 2m 32s\n",
      "1800:\ttotal: 11m 27s\tremaining: 1m 13s\n",
      "1991:\ttotal: 12m 24s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# =====================\n",
    "# Load data\n",
    "# =====================\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "TARGET = 'diagnosed_diabetes'\n",
    "ID_COL = 'id'\n",
    "\n",
    "X = train.drop(columns=[TARGET])\n",
    "y = train[TARGET]\n",
    "\n",
    "# =====================\n",
    "# Identify categorical features\n",
    "# =====================\n",
    "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_feature_indices = [X.columns.get_loc(col) for col in cat_features]\n",
    "\n",
    "# =====================\n",
    "# Cross-validation to validate AUC\n",
    "# =====================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=2000,\n",
    "        learning_rate=0.03,\n",
    "        depth=8,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        l2_leaf_reg=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bylevel=0.8,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=200\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_val, y_val),\n",
    "        cat_features=cat_feature_indices,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_preds)\n",
    "    auc_scores.append(auc)\n",
    "    oof_preds[val_idx] = val_preds\n",
    "\n",
    "    test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    print(f\"Fold {fold + 1} AUC: {auc:.5f}\")\n",
    "\n",
    "print(\"\\nMean CV AUC:\", np.mean(auc_scores))\n",
    "\n",
    "# =====================\n",
    "# Train final model on full data\n",
    "# =====================\n",
    "final_model = CatBoostClassifier(\n",
    "    iterations=int(np.mean([model.best_iteration_ for _ in range(1)])),\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    l2_leaf_reg=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bylevel=0.8,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "final_model.fit(X, y, cat_features=cat_feature_indices)\n",
    "\n",
    "final_test_preds = final_model.predict_proba(test)[:, 1]\n",
    "\n",
    "# =====================\n",
    "# Create submission\n",
    "# =====================\n",
    "submission = sample_sub.copy()\n",
    "submission[TARGET] = final_test_preds\n",
    "submission.to_csv('submission5.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8b19754",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 68\u001b[0m\n\u001b[1;32m     48\u001b[0m val_pool \u001b[38;5;241m=\u001b[39m Pool(X_val, y_val, cat_features\u001b[38;5;241m=\u001b[39mcat_feature_indices)\n\u001b[1;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\n\u001b[1;32m     51\u001b[0m     iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6000\u001b[39m,\n\u001b[1;32m     52\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.015\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 68\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_pool, eval_set\u001b[38;5;241m=\u001b[39mval_pool, use_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     71\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_val, val_pred)\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.12/site-packages/catboost/core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, cat_features, text_features, embedding_features, \u001b[38;5;28;01mNone\u001b[39;00m, graph, sample_weight, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, baseline, use_best_model,\n\u001b[1;32m   5246\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5247\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.12/site-packages/catboost/core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(\n\u001b[1;32m   2411\u001b[0m         train_pool,\n\u001b[1;32m   2412\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_sets\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   2413\u001b[0m         params,\n\u001b[1;32m   2414\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2415\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2416\u001b[0m     )\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/miniconda3/envs/data/lib/python3.12/site-packages/catboost/core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[38;5;241m.\u001b[39m_object \u001b[38;5;28;01mif\u001b[39;00m init_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:5023\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:5072\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ultra-optimized AUC model (Leaderboard-oriented)\n",
    "# Techniques used:\n",
    "# - CatBoost with ordered boosting\n",
    "# - Strong regularization\n",
    "# - CV-based optimal iteration selection\n",
    "# - Test-time averaging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# =====================\n",
    "# Load data\n",
    "# =====================\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "TARGET = 'diagnosed_diabetes'\n",
    "ID_COL = 'id'\n",
    "\n",
    "X = train.drop(columns=[TARGET])\n",
    "y = train[TARGET]\n",
    "\n",
    "# =====================\n",
    "# Categorical features\n",
    "# =====================\n",
    "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_feature_indices = [X.columns.get_loc(c) for c in cat_features]\n",
    "\n",
    "# =====================\n",
    "# CV setup\n",
    "# =====================\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(test))\n",
    "best_iterations = []\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_indices)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=cat_feature_indices)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=6000,\n",
    "        learning_rate=0.015,\n",
    "        depth=9,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        l2_leaf_reg=10,\n",
    "        colsample_bylevel=0.85,\n",
    "        boosting_type='Ordered',\n",
    "        bootstrap_type='Bayesian',\n",
    "        bagging_temperature=0.5,\n",
    "        min_data_in_leaf=50,\n",
    "        grow_policy='SymmetricTree',\n",
    "        early_stopping_rounds=400,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "\n",
    "    auc_scores.append(auc)\n",
    "    best_iterations.append(model.best_iteration_)\n",
    "    oof[val_idx] = val_pred\n",
    "\n",
    "    test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    print(f\"Fold {fold + 1} | AUC = {auc:.6f} | Best iter = {model.best_iteration_}\")\n",
    "\n",
    "print(\"\\nMean CV AUC:\", np.mean(auc_scores))\n",
    "print(\"Mean best iteration:\", int(np.mean(best_iterations)))\n",
    "\n",
    "# =====================\n",
    "# Final model (full data)\n",
    "# =====================\n",
    "final_model = CatBoostClassifier(\n",
    "    iterations=int(np.mean(best_iterations)),\n",
    "    learning_rate=0.015,\n",
    "    depth=9,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    l2_leaf_reg=10,\n",
    "    colsample_bylevel=0.85,\n",
    "    boosting_type='Ordered',\n",
    "    bootstrap_type='Bayesian',\n",
    "    bagging_temperature=0.5,\n",
    "    min_data_in_leaf=50,\n",
    "    grow_policy='SymmetricTree',\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "final_model.fit(X, y, cat_features=cat_feature_indices)\n",
    "\n",
    "final_test_preds = final_model.predict_proba(test)[:, 1]\n",
    "\n",
    "# =====================\n",
    "# Submission\n",
    "# =====================\n",
    "submission = sample_sub.copy()\n",
    "submission[TARGET] = final_test_preds\n",
    "submission.to_csv('submission6.csv', index=False)\n",
    "\n",
    "print(\"Ultra-optimized submission saved \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST & STRONG CatBoost model (≈95% of max AUC, 4x faster)\n",
    "# Competition-safe configuration\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# =====================\n",
    "# Load data\n",
    "# =====================\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "TARGET = 'diagnosed_diabetes'\n",
    "\n",
    "X = train.drop(columns=[TARGET])\n",
    "y = train[TARGET]\n",
    "\n",
    "# =====================\n",
    "# Categorical features\n",
    "# =====================\n",
    "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_feature_indices = [X.columns.get_loc(c) for c in cat_features]\n",
    "\n",
    "# =====================\n",
    "# CV setup (FAST)\n",
    "# =====================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "test_preds = np.zeros(len(test))\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_indices)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=cat_feature_indices)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.02,\n",
    "        depth=8,\n",
    "        loss_function='Logloss',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        l2_leaf_reg=7,\n",
    "        boosting_type='Ordered',\n",
    "        bootstrap_type='Bayesian',\n",
    "        bagging_temperature=0.3,\n",
    "        min_data_in_leaf=40,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=200\n",
    "    )\n",
    "\n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "    val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "    test_preds += model.predict_proba(test)[:, 1] / skf.n_splits\n",
    "\n",
    "    print(f\"Fold {fold + 1} AUC: {auc:.6f}\")\n",
    "\n",
    "print(\"\\nMean CV AUC:\", np.mean(auc_scores))\n",
    "\n",
    "# =====================\n",
    "# Submission\n",
    "# =====================\n",
    "submission = sample_sub.copy()\n",
    "submission[TARGET] = test_preds\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"FAST submission saved ✔\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

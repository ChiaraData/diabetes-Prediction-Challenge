{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e1a2fd",
   "metadata": {},
   "source": [
    "# Diabetes Prediction â€“ Kaggle Playground Series S5E12\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook is part of the Kaggle competition **Playground Series - Season 5, Episode 12**.\n",
    "The goal is to build a machine learning model capable of predicting whether a patient has diabetes based on medical features.\n",
    "\n",
    "This project demonstrates the full data science workflow:\n",
    "- Data exploration\n",
    "- Feature preprocessing\n",
    "- Model training\n",
    "- Performance evaluation\n",
    "\n",
    "This notebook is intended both for competition purposes and as a **portfolio project**.\n",
    "\n",
    "kaggle : https://www.kaggle.com/competitions/playground-series-s5e12/data?select=test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3181280",
   "metadata": {},
   "source": [
    "## Libraries Import and Data Loading\n",
    "\n",
    "We start by importing the necessary Python libraries for data manipulation, visualization, and machine learning.\n",
    "\n",
    "The dataset is provided by Kaggle and consists of:\n",
    "- A training set with features and target variable\n",
    "- A test set without labels, used for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d05467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data charged with sucess!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv('data/train.csv')\n",
    "    df_test = pd.read_csv('data/test.csv')\n",
    "    print(\"Data charged with sucess!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Files not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c591be",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we explore the dataset to better understand:\n",
    "- Data structure\n",
    "- Feature distributions\n",
    "- Missing values\n",
    "- Potential outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecde4db",
   "metadata": {},
   "source": [
    "### Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb924fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700000 entries, 0 to 699999\n",
      "Data columns (total 26 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   id                                  700000 non-null  int64  \n",
      " 1   age                                 700000 non-null  int64  \n",
      " 2   alcohol_consumption_per_week        700000 non-null  int64  \n",
      " 3   physical_activity_minutes_per_week  700000 non-null  int64  \n",
      " 4   diet_score                          700000 non-null  float64\n",
      " 5   sleep_hours_per_day                 700000 non-null  float64\n",
      " 6   screen_time_hours_per_day           700000 non-null  float64\n",
      " 7   bmi                                 700000 non-null  float64\n",
      " 8   waist_to_hip_ratio                  700000 non-null  float64\n",
      " 9   systolic_bp                         700000 non-null  int64  \n",
      " 10  diastolic_bp                        700000 non-null  int64  \n",
      " 11  heart_rate                          700000 non-null  int64  \n",
      " 12  cholesterol_total                   700000 non-null  int64  \n",
      " 13  hdl_cholesterol                     700000 non-null  int64  \n",
      " 14  ldl_cholesterol                     700000 non-null  int64  \n",
      " 15  triglycerides                       700000 non-null  int64  \n",
      " 16  gender                              700000 non-null  object \n",
      " 17  ethnicity                           700000 non-null  object \n",
      " 18  education_level                     700000 non-null  object \n",
      " 19  income_level                        700000 non-null  object \n",
      " 20  smoking_status                      700000 non-null  object \n",
      " 21  employment_status                   700000 non-null  object \n",
      " 22  family_history_diabetes             700000 non-null  int64  \n",
      " 23  hypertension_history                700000 non-null  int64  \n",
      " 24  cardiovascular_history              700000 non-null  int64  \n",
      " 25  diagnosed_diabetes                  700000 non-null  float64\n",
      "dtypes: float64(6), int64(14), object(6)\n",
      "memory usage: 138.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ee19a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>349999.500000</td>\n",
       "      <td>50.359734</td>\n",
       "      <td>2.072411</td>\n",
       "      <td>80.230803</td>\n",
       "      <td>5.963695</td>\n",
       "      <td>7.002200</td>\n",
       "      <td>6.012733</td>\n",
       "      <td>25.874684</td>\n",
       "      <td>0.858766</td>\n",
       "      <td>116.294193</td>\n",
       "      <td>75.440924</td>\n",
       "      <td>70.167749</td>\n",
       "      <td>186.818801</td>\n",
       "      <td>53.823214</td>\n",
       "      <td>102.905854</td>\n",
       "      <td>123.081850</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.181990</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>0.623296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>202072.738554</td>\n",
       "      <td>11.655520</td>\n",
       "      <td>1.048189</td>\n",
       "      <td>51.195071</td>\n",
       "      <td>1.463336</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>2.022707</td>\n",
       "      <td>2.860705</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>11.010390</td>\n",
       "      <td>6.825775</td>\n",
       "      <td>6.938722</td>\n",
       "      <td>16.730832</td>\n",
       "      <td>8.266545</td>\n",
       "      <td>19.022416</td>\n",
       "      <td>24.739397</td>\n",
       "      <td>0.356484</td>\n",
       "      <td>0.385837</td>\n",
       "      <td>0.171478</td>\n",
       "      <td>0.484560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>174999.750000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>349999.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>524999.250000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>699999.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            age  alcohol_consumption_per_week  \\\n",
       "count  700000.000000  700000.000000                 700000.000000   \n",
       "mean   349999.500000      50.359734                      2.072411   \n",
       "std    202072.738554      11.655520                      1.048189   \n",
       "min         0.000000      19.000000                      1.000000   \n",
       "25%    174999.750000      42.000000                      1.000000   \n",
       "50%    349999.500000      50.000000                      2.000000   \n",
       "75%    524999.250000      58.000000                      3.000000   \n",
       "max    699999.000000      89.000000                      9.000000   \n",
       "\n",
       "       physical_activity_minutes_per_week     diet_score  sleep_hours_per_day  \\\n",
       "count                       700000.000000  700000.000000        700000.000000   \n",
       "mean                            80.230803       5.963695             7.002200   \n",
       "std                             51.195071       1.463336             0.901907   \n",
       "min                              1.000000       0.100000             3.100000   \n",
       "25%                             49.000000       5.000000             6.400000   \n",
       "50%                             71.000000       6.000000             7.000000   \n",
       "75%                             96.000000       7.000000             7.600000   \n",
       "max                            747.000000       9.900000             9.900000   \n",
       "\n",
       "       screen_time_hours_per_day            bmi  waist_to_hip_ratio  \\\n",
       "count              700000.000000  700000.000000       700000.000000   \n",
       "mean                    6.012733      25.874684            0.858766   \n",
       "std                     2.022707       2.860705            0.037980   \n",
       "min                     0.600000      15.100000            0.680000   \n",
       "25%                     4.600000      23.900000            0.830000   \n",
       "50%                     6.000000      25.900000            0.860000   \n",
       "75%                     7.400000      27.800000            0.880000   \n",
       "max                    16.500000      38.400000            1.050000   \n",
       "\n",
       "         systolic_bp   diastolic_bp     heart_rate  cholesterol_total  \\\n",
       "count  700000.000000  700000.000000  700000.000000      700000.000000   \n",
       "mean      116.294193      75.440924      70.167749         186.818801   \n",
       "std        11.010390       6.825775       6.938722          16.730832   \n",
       "min        91.000000      51.000000      42.000000         117.000000   \n",
       "25%       108.000000      71.000000      65.000000         175.000000   \n",
       "50%       116.000000      75.000000      70.000000         187.000000   \n",
       "75%       124.000000      80.000000      75.000000         199.000000   \n",
       "max       163.000000     104.000000     101.000000         289.000000   \n",
       "\n",
       "       hdl_cholesterol  ldl_cholesterol  triglycerides  \\\n",
       "count    700000.000000    700000.000000  700000.000000   \n",
       "mean         53.823214       102.905854     123.081850   \n",
       "std           8.266545        19.022416      24.739397   \n",
       "min          21.000000        51.000000      31.000000   \n",
       "25%          48.000000        89.000000     106.000000   \n",
       "50%          54.000000       103.000000     123.000000   \n",
       "75%          59.000000       116.000000     139.000000   \n",
       "max          90.000000       205.000000     290.000000   \n",
       "\n",
       "       family_history_diabetes  hypertension_history  cardiovascular_history  \\\n",
       "count            700000.000000         700000.000000           700000.000000   \n",
       "mean                  0.149401              0.181990                0.030324   \n",
       "std                   0.356484              0.385837                0.171478   \n",
       "min                   0.000000              0.000000                0.000000   \n",
       "25%                   0.000000              0.000000                0.000000   \n",
       "50%                   0.000000              0.000000                0.000000   \n",
       "75%                   0.000000              0.000000                0.000000   \n",
       "max                   1.000000              1.000000                1.000000   \n",
       "\n",
       "       diagnosed_diabetes  \n",
       "count       700000.000000  \n",
       "mean             0.623296  \n",
       "std              0.484560  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              1.000000  \n",
       "75%              1.000000  \n",
       "max              1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0515b6f",
   "metadata": {},
   "source": [
    "### First observation \n",
    "The maximum BMI is consistent with obesity and diabetes, and the blood pressure and physical activity ranges are entirely plausible. All numerical columns are normal, and the target variable is confirmed to be binary (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4765aab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- gender ---\n",
      "gender\n",
      "Female    363237\n",
      "Male      333085\n",
      "Other       3678\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- ethnicity ---\n",
      "ethnicity\n",
      "White       386153\n",
      "Hispanic    129984\n",
      "Black       106301\n",
      "Asian        60120\n",
      "Other        17442\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- education_level ---\n",
      "education_level\n",
      "Highschool      344145\n",
      "Graduate        261268\n",
      "Postgraduate     79642\n",
      "No formal        14945\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- income_level ---\n",
      "income_level\n",
      "Middle          290557\n",
      "Lower-Middle    178570\n",
      "Upper-Middle    127836\n",
      "Low              85803\n",
      "High             17234\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- smoking_status ---\n",
      "smoking_status\n",
      "Never      494448\n",
      "Current    103363\n",
      "Former     102189\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- employment_status ---\n",
      "employment_status\n",
      "Employed      516170\n",
      "Retired       115735\n",
      "Unemployed     49787\n",
      "Student        18308\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\n",
    "    'gender', \n",
    "    'ethnicity', \n",
    "    'education_level', \n",
    "    'income_level', \n",
    "    'smoking_status', \n",
    "    'employment_status'\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(df_train[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1eaf68",
   "metadata": {},
   "source": [
    "##  Data Preprocessing\n",
    "\n",
    "Before training the models, several preprocessing steps are applied:\n",
    "- Handling missing values\n",
    "- Feature scaling\n",
    "- Encoding if necessary\n",
    "\n",
    "These steps ensure that the data is suitable for machine learning algorithms.\n",
    "\n",
    "\n",
    "Label Encoding : `education_level` , `income_level`, `smoking_statut`\n",
    "\n",
    "\n",
    "One-Hot Encoding : `gender`, `ethnicity`, `employment_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66798f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 lines of the dataset after income_level encoding:\n",
      "   income_level  income_level_encoded\n",
      "0  Lower-Middle                     2\n",
      "1  Upper-Middle                     4\n",
      "2  Lower-Middle                     2\n",
      "3  Lower-Middle                     2\n",
      "4  Upper-Middle                     4\n"
     ]
    }
   ],
   "source": [
    "income_mapping = {\n",
    "    'Low': 1,\n",
    "    'Lower-Middle': 2,\n",
    "    'Middle': 3,\n",
    "    'Upper-Middle': 4,\n",
    "    'High': 5\n",
    "}\n",
    "\n",
    "df_train['income_level_encoded'] = df_train['income_level'].map(income_mapping)\n",
    "\n",
    "print(\"The first 5 lines of the dataset after income_level encoding:\")\n",
    "print(df_train[['income_level', 'income_level_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd8d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 lines of the dataset after education_level encoding:\n",
      "  education_level  education_level_encoded\n",
      "0      Highschool                        1\n",
      "1      Highschool                        1\n",
      "2      Highschool                        1\n",
      "3      Highschool                        1\n",
      "4      Highschool                        1\n"
     ]
    }
   ],
   "source": [
    "education_mapping = {\n",
    "    'No formal': 0,\n",
    "    'Highschool': 1,\n",
    "    'Graduate': 2,\n",
    "    'Postgraduate': 3\n",
    "}\n",
    "\n",
    "df_train['education_level_encoded'] = df_train['education_level'].map(education_mapping)\n",
    "\n",
    "print(\"The first 5 lines of the dataset after education_level encoding:\")\n",
    "print(df_train[['education_level', 'education_level_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6a3527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 lines of the dataset after smoking_status encoding:\n",
      "  smoking_status  smoking_status_encoded\n",
      "0        Current                       1\n",
      "1          Never                       0\n",
      "2          Never                       0\n",
      "3        Current                       1\n",
      "4          Never                       0\n"
     ]
    }
   ],
   "source": [
    "smoking_mapping = {\n",
    "    'Never': 0,\n",
    "    'Current': 1,\n",
    "    'Former': 2\n",
    "}\n",
    "\n",
    "df_train['smoking_status_encoded'] = df_train['smoking_status'].map(smoking_mapping)\n",
    "\n",
    "print(\"The first 5 lines of the dataset after smoking_status encoding:\")\n",
    "print(df_train[['smoking_status', 'smoking_status_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8454690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cols = ['gender', 'ethnicity', 'employment_status']\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=nominal_cols, drop_first=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc642e",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55f61724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['cholesterol_ratio'] = df_train['ldl_cholesterol'] / df_train['hdl_cholesterol']\n",
    "\n",
    "df_train['mean_blood_pressure'] = (df_train['systolic_bp'] + df_train['diastolic_bp']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23caa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi',\n",
    "    'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate',\n",
    "    'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides','cholesterol_ratio','mean_blood_pressure'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_train[numerical_cols] = scaler.fit_transform(df_train[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57daf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['id', 'income_level', 'education_level', 'smoking_status']\n",
    "df_train = df_train.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d948e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features = df_train.drop(columns=['diagnosed_diabetes']).columns.tolist()\n",
    "len(final_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46833589",
   "metadata": {},
   "source": [
    "## Train-Validation Split\n",
    "\n",
    "The dataset is split into training and validation sets in order to evaluate model performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e9a771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train training set size: (560000, 32)\n",
      " X_val X_train validation set size: (140000, 32)\n",
      "X_train training set size y_train: (560000,)\n",
      "y_val validation set size: (140000,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train.drop(columns=['diagnosed_diabetes'])\n",
    "y = df_train['diagnosed_diabetes']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"X_train training set size: {X_train.shape}\")\n",
    "print(f\" X_val X_train validation set size: {X_val.shape}\")\n",
    "print(f\"X_train training set size y_train: {y_train.shape}\")\n",
    "print(f\"y_val validation set size: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f449a2",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Several machine learning models are trained and compared.\n",
    "The objective is to identify the model that provides the best ROC AUC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d11e0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC score of Gradient Boosting across the validation set: 0.70709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = gb_classifier.predict_proba(X_val)[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "print(f\"AUC-ROC score of Gradient Boosting across the validation set: {auc_roc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4bf8a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting of Grid Search...\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time= 2.5min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time= 2.5min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time= 2.5min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=150, subsample=0.8; total time= 3.8min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=150, subsample=0.8; total time= 3.8min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=150, subsample=0.8; total time= 3.9min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time= 5.1min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time= 5.2min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time= 2.7min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time= 5.4min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=250, subsample=0.8; total time= 6.9min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=250, subsample=0.8; total time= 6.9min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=250, subsample=0.8; total time= 6.9min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time= 2.9min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time= 2.9min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8; total time= 8.2min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8; total time= 8.2min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=150, subsample=0.8; total time= 4.1min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8; total time= 8.3min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=150, subsample=0.8; total time= 4.1min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=150, subsample=0.8; total time= 4.1min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time= 5.4min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time= 5.5min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time= 5.7min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=250, subsample=0.8; total time= 7.1min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.0min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=250, subsample=0.8; total time= 7.3min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=250, subsample=0.8; total time= 7.3min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.1min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time= 8.9min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.3min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time= 9.6min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.3min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=10.2min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.6min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.7min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=200, subsample=0.8; total time= 7.3min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=200, subsample=0.8; total time= 7.6min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=200, subsample=0.8; total time= 7.6min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=250, subsample=0.8; total time= 9.1min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.5min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.5min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=250, subsample=0.8; total time= 9.1min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=250, subsample=0.8; total time= 8.9min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=300, subsample=0.8; total time=10.7min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=300, subsample=0.8; total time=10.7min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.7min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.5min\n",
      "[CV] END learning_rate=0.15, max_depth=3, n_estimators=300, subsample=0.8; total time=10.9min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.5min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.5min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time= 7.2min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time= 7.1min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time= 7.1min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=250, subsample=0.8; total time= 8.6min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.1min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=250, subsample=0.8; total time= 8.3min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.2min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=250, subsample=0.8; total time= 8.4min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=100, subsample=0.8; total time= 3.3min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=10.0min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=10.0min\n",
      "[CV] END learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time= 9.7min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.0min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.0min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=150, subsample=0.8; total time= 5.0min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=200, subsample=0.8; total time= 6.8min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=200, subsample=0.8; total time= 6.8min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=200, subsample=0.8; total time= 6.9min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=250, subsample=0.8; total time= 8.2min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=250, subsample=0.8; total time= 7.5min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=250, subsample=0.8; total time= 7.5min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=300, subsample=0.8; total time= 8.3min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=300, subsample=0.8; total time= 8.3min\n",
      "[CV] END learning_rate=0.25, max_depth=3, n_estimators=300, subsample=0.8; total time= 7.0min\n",
      "\n",
      "Grid Search results:\n",
      "Best score: 0.72436\n",
      "Best hyperparameters : {'learning_rate': 0.25, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Final AUC-ROC score across the validation set (with optimized hyperparameters) : 0.72527\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],  \n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25], \n",
    "    'max_depth': [3], \n",
    "    'subsample': [0.8], \n",
    "}\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gb_model, \n",
    "    param_grid=param_grid, \n",
    "    scoring='roc_auc', \n",
    "    cv=3, \n",
    "    verbose=2, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting of Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nGrid Search results:\")\n",
    "print(f\"Best score: {grid_search.best_score_:.5f}\")\n",
    "print(f\"Best hyperparameters : {grid_search.best_params_}\")\n",
    "\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "y_pred_proba_tuned = best_gb_model.predict_proba(X_val)[:, 1]\n",
    "final_auc_roc = roc_auc_score(y_val, y_pred_proba_tuned)\n",
    "\n",
    "print(f\"Final AUC-ROC score across the validation set (with optimized hyperparameters) : {final_auc_roc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac499fa",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Models are evaluated using ROC AUC on the validation set.\n",
    "This allows us to compare performance and detect potential overfitting.\n",
    "\n",
    "The fact that the overall validation score (0.72527) is very close to the best cross-validation score (0.72436) is a sign of stability and confirms that the model is not significantly overfitting.\n",
    "\n",
    "The best hyperparameters found are:\n",
    "\n",
    "learning_rate: 0.25\n",
    "\n",
    "n_estimators: 300\n",
    "\n",
    "This shows that the model benefits from a faster learning rate and a larger number of trees to achieve this performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711cf21",
   "metadata": {},
   "source": [
    "##  Final Model & Kaggle Submission\n",
    "\n",
    "The best-performing model is selected to generate predictions on the test dataset.\n",
    "These predictions are then formatted according to Kaggle submission requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a6ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   id                                  300000 non-null  int64  \n",
      " 1   age                                 300000 non-null  int64  \n",
      " 2   alcohol_consumption_per_week        300000 non-null  int64  \n",
      " 3   physical_activity_minutes_per_week  300000 non-null  int64  \n",
      " 4   diet_score                          300000 non-null  float64\n",
      " 5   sleep_hours_per_day                 300000 non-null  float64\n",
      " 6   screen_time_hours_per_day           300000 non-null  float64\n",
      " 7   bmi                                 300000 non-null  float64\n",
      " 8   waist_to_hip_ratio                  300000 non-null  float64\n",
      " 9   systolic_bp                         300000 non-null  int64  \n",
      " 10  diastolic_bp                        300000 non-null  int64  \n",
      " 11  heart_rate                          300000 non-null  int64  \n",
      " 12  cholesterol_total                   300000 non-null  int64  \n",
      " 13  hdl_cholesterol                     300000 non-null  int64  \n",
      " 14  ldl_cholesterol                     300000 non-null  int64  \n",
      " 15  triglycerides                       300000 non-null  int64  \n",
      " 16  gender                              300000 non-null  object \n",
      " 17  ethnicity                           300000 non-null  object \n",
      " 18  education_level                     300000 non-null  object \n",
      " 19  income_level                        300000 non-null  object \n",
      " 20  smoking_status                      300000 non-null  object \n",
      " 21  employment_status                   300000 non-null  object \n",
      " 22  family_history_diabetes             300000 non-null  int64  \n",
      " 23  hypertension_history                300000 non-null  int64  \n",
      " 24  cardiovascular_history              300000 non-null  int64  \n",
      "dtypes: float64(5), int64(14), object(6)\n",
      "memory usage: 57.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "742984bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "income_mapping = {'Low': 1, 'Lower-Middle': 2, 'Middle': 3, 'Upper-Middle': 4, 'High': 5}\n",
    "education_mapping = {'No formal': 0, 'Highschool': 1, 'Graduate': 2, 'Postgraduate': 3}\n",
    "smoking_mapping = {'Never': 0, 'Current': 1, 'Former': 2}\n",
    "nominal_cols = ['gender', 'ethnicity', 'employment_status']\n",
    "numerical_cols = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi',\n",
    "    'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate',\n",
    "    'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides','cholesterol_ratio','mean_blood_pressure'\n",
    "]\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "test_ids = df_test['id'] \n",
    "\n",
    "df_test['cholesterol_ratio'] = df_test['ldl_cholesterol'] / df_test['hdl_cholesterol']\n",
    "df_test['mean_blood_pressure'] = (df_test['systolic_bp'] + df_test['diastolic_bp']) / 2\n",
    "\n",
    "df_test['income_level_encoded'] = df_test['income_level'].map(income_mapping)\n",
    "df_test['education_level_encoded'] = df_test['education_level'].map(education_mapping)\n",
    "df_test['smoking_status_encoded'] = df_test['smoking_status'].map(smoking_mapping)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=nominal_cols, drop_first=True, dtype=int)\n",
    "\n",
    "df_test[numerical_cols] = scaler.transform(df_test[numerical_cols])\n",
    "\n",
    "cols_to_drop = [\n",
    "    'id', \n",
    "    'income_level', \n",
    "    'education_level', \n",
    "    'smoking_status'\n",
    "]\n",
    "df_test = df_test.drop(columns=cols_to_drop, errors='ignore') \n",
    "\n",
    "\n",
    "\n",
    "X_test_final = df_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "\n",
    "predictions = best_gb_model.predict_proba(X_test_final)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "694aa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': predictions})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
